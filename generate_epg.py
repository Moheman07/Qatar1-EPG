#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import io
import re
import json
import time
import requests
from datetime import datetime, timedelta
import warnings
from requests.packages.urllib3.exceptions import InsecureRequestWarning
import fileinput

input_path = "qatar1.xml"
output_path = "out.xml"
providers_file = "providers.json"

warnings.filterwarnings('ignore', category=InsecureRequestWarning)

List_Chang = []

def download_epg():
    url = "https://www.open-epg.com/files/qatar1.xml"
    print("â¬‡ï¸ Downloading EPG file...")
    response = requests.get(url, verify=False)
    if response.status_code == 200:
        with io.open(input_path, 'w', encoding='utf-8') as f:
            f.write(response.content.decode('utf-8'))
        print("âœ… Download successful.")
    else:
        raise Exception(f"Failed to download EPG: {response.status_code}")

def apply_changes():
    # Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹ Ù‚Ø§Ø¦Ù…Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„ØªØµÙ†ÙŠÙ
    categories = {
        'Premier League': 'Football',
        'Formula 1': 'Motorsport',
        'UEFA Champions League': 'Football',
        'Bundesliga': 'Football',
        'La Liga': 'Football',
        'NBA': 'Basketball',
        'AFC': 'Football',
        'EFL': 'Football'
        # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© ØªØµÙ†ÙŠÙØ§Øª Ø£Ø®Ø±Ù‰ Ù‡Ù†Ø§
    }

    for old_text, new_text in List_Chang:
        for line in fileinput.input(input_path, inplace=True):
            line = line.replace(old_text, new_text)
            print(line, end='')

    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø¥Ù„Ù‰ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬
    with open(input_path, 'r', encoding='utf-8') as f:
        xml_data = f.read()

    def add_category_to_programme(match):
        title = match.group(1)
        category = categories.get(title, 'Other')  # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙˆÙØ± ØªØµÙ†ÙŠÙØŒ Ø³ÙŠØªÙ… ØªØµÙ†ÙŠÙÙ‡ ÙƒÙ€ 'Other'
        return f'<programme start="{match.group(2)}" stop="{match.group(3)}" channel="{match.group(4)}">\n<title>{title}</title>\n<category>{category}</category>\n<desc>{match.group(5)}</desc>\n</programme>'

    # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬ ÙˆØ¥Ø¶Ø§ÙØ© Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª
    xml_data = re.sub(r'<programme start="(\d{14}) \+0000" stop="(\d{14}) \+0000" channel="([^"]+)"><title>([^<]+)</title><desc>([^<]+)</desc>', add_category_to_programme, xml_data)

    # Ø­ÙØ¸ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª ÙÙŠ Ø§Ù„Ù…Ù„Ù
    with open(input_path, 'w', encoding='utf-8') as f:
        f.write(xml_data)
    print("âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ù„Ù„Ø¨Ø±Ø§Ù…Ø¬.")

def adjust_times():
    with io.open(input_path, 'r', encoding='utf-8') as f:
        xml_data = f.read()

    def adjust_time(match, attr):
        original_time = datetime.strptime(match.group(1), '%Y%m%d%H%M%S')
        # Ø®ØµÙ… 3 Ø³Ø§Ø¹Ø§Øª Ù…Ù† Ø§Ù„ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø£ØµÙ„ÙŠ
        adjusted_time = original_time - timedelta(hours=3)
        return f'{attr}="{adjusted_time.strftime("%Y%m%d%H%M%S")} +0000"'

    xml_data = re.sub(r'start="(\d{14}) \+0000"', lambda m: adjust_time(m, 'start'), xml_data)
    xml_data = re.sub(r'stop="(\d{14}) \+0000"', lambda m: adjust_time(m, 'stop'), xml_data)

    with io.open(input_path, 'w', encoding='utf-8') as f:
        f.write(xml_data)

    print("ğŸ•“ ØªÙ… ØªØ¹Ø¯ÙŠÙ„ ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬ Ø¯Ø§Ø®Ù„ XML (-3 Ø³Ø§Ø¹Ø§Øª)")

def remove_duplicates():
    seen = set()
    with open(output_path, 'w', encoding='utf-8') as out:
        for line in open(input_path, 'r', encoding='utf-8'):
            if line not in seen:
                out.write(line)
                seen.add(line)

def rename_final():
    os.remove(input_path)
    os.rename(output_path, input_path)
    print("ğŸ“ Ù…Ù„Ù XML Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ØªÙ… Ø­ÙØ¸Ù‡.")

def update_provider_info():
    if not os.path.exists(providers_file):
        print("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù providers.json.")
        return
    with open(providers_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    for ch in data.get('bouquets', []):
        if ch.get('bouquet') == 'qatar1iet5':
            ch['date'] = datetime.now().strftime('%A %d %B %Y - %H:%M')
    with open(providers_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4, ensure_ascii=False)

def clean_xml():
    with open(input_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    with open(input_path, 'w', encoding='utf-8') as f:
        for line in lines:
            if all(tag not in line for tag in ['<icon src="https://', '<url>https://', '<category']) and line.strip():
                f.write(line)

def main():
    try:
        download_epg()
        with open(input_path, 'r', encoding='utf-8') as f:
            content = f.read()
            print(f"ğŸ“º Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ù†ÙˆØ§Øª: {content.count('<channel id=\"')}")
        apply_changes()
        adjust_times()
        remove_duplicates()
        rename_final()
        update_provider_info()
        clean_xml()
        print("âœ… EPG generation complete.")
    except Exception as e:
        print(f"âŒ Error: {e}")

if __name__ == "__main__":
    main()
